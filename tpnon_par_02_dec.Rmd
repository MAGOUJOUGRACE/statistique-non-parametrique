---
title: "TP_non_par02dec"
author: "MAGOUJOU Macdonie Grace"
date: "02/12/2022"
output: html_document
---

```{r}
library(MASS)
library(dplyr)
```


# EXERCICE 2

```{r}
n=1000
x= seq(-1,2,l=2000)
z = rbeta(n,shape1 = 1.9,shape2 = 1.9)
dz =  dbeta(x,shape1 = 1.9,shape2 = 1.9)
plot(x,dz,t='l',col='red')

```

```{r}
for(D in c(5,15,20,25,30,35,40,45,50,100)){
  hist(z,D,freq = FALSE) # histogramme en densité de probabilité,attention frequency veut dire effectif en anglais
  fhat = hist(z,D,freq = FALSE)$density
}
```

```{r}
par(nfrow=c(2,2))
for(D in c(5,15,50,300)){
  fhat= hist(z,D,freq = F,col='red')$density
}
```

```{r}
v= vector(mode = "numeric", length = 23)#Vecteur de variances
B2 = vector(mode = "numeric", length = 23)# vecteur des termes de biais^2
D=c(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25)
for(i in 1:23)
{
  a  = vector(mode = "numeric", length = D[i])
  for (j in c(1:D[i]))
  {
    a[j]  = pbeta(j/D[i],shape1 = 1.9,shape2 = 1.9)-pbeta((j-1)/D[i],shape1 = 1.9,shape2 = 1.9)
  }
  v[i] = sum(a*(1-a))*D[i]/n
  B2[i]= -D[i]*sum(a^2) #D[i] ok
} 

plot(D,B2)
plot(D,v)
plot(D,v+B2)
which.min(v+B2) +2 #(on a commencé à D=3) pour avoir le bon nombre de sous-intervalles est D = 12 .
#Rq le calcul du biais a nécéssité la connaissance de la loi (Contexte de simulation)

```




## Une fonction pour le choix des classes d'un histogramme régulier (Birgé-Rozenholc)
```{r}
HISTSELECT2= function(x,A=min(x),B=max(x), col=NULL, border="black", freq=TRUE,  right=TRUE, xlab = deparse(substitute(x)), ylab=NA, main=paste("Histogram of", deparse(substitute(x))), nmax=NA)
{ if(is.na(ylab)){if(freq==TRUE){ylab="Frequency"}else{ylab="Density"}}
  if(A>=B){cat("The limits of the chosen interval are not consistent")}
  else
  {
    n<-length(x)
    a<-min(x)
    b<-max(x)
    a2<-max(a,A)
    b2<-min(b,B)
    if(B<=a | A >=b){cat("There are no observations in the chosen interval")}
    else{
      y<-(x<a2|x>b2)
      n2<-table(y)[1]
      if(is.na(nmax)){nmax<-min(floor(n2/log(max(n2,exp(1)))), 250)}
      #if(is.na(nmax)){nmax<-min(floor(0.3+n2^(0.575)),150)}
      L <- vector(mode="numeric", length=nmax)
      for(D in 1:nmax)
      {
        bins<-a2+(b2-a2)*seq(0,1,1/D)
        N<-hist(x[y==FALSE], breaks=bins, right=right, plot=FALSE)$count
        #if(n2<150){pen<--D+1-(log(D))^(n*2.5/150)}else{pen<--D+1-(log(D))^(2.5)}
        pen<--D+1-(log(D))^(2.5)
        L[D]<-sum(N*log(pmax(N,1)))+n2*log(D)+pen
      }
      D1<-which.max(L)
      D2<-order(L)[2]
      D3<-order(L)[3]
      if(n2<15){Dstar<-D1}
      if(n2>14&n2<41){if(D1>1){Dstar<-D1}else{Dstar<-D2}}
      if(n2>40){if(D1>2){Dstar<-D1}else{if(D2>2){Dstar<-D2}else{Dstar<-D3}}}
      cat("Number of observations in the chosen interval:", n2, "\n")
      cat("Partition size:", Dstar, "\n")
      if(a2==a&b2==b)
      {
        hist(x,breaks=a2+(b2-a2)*seq(0,1,1/Dstar),freq=freq, right=right, xlim=c(a2,b2), col=col, border=border,xlab=xlab, ylab=ylab, main=main)
      }
      if(a2>a&b2==b)
      {
        a3<-a2-ceiling((a2-a)/((b2-a2)/Dstar))*(b2-a2)/Dstar
        hist(x,breaks=seq(a3,b2,(b2-a2)/Dstar),freq=freq, right=right, xlim=c(a2,b2),col=col, border=border, xlab=xlab, ylab=ylab, main=main)
        points(a2,0,col="black",pch=20)
      }
      if(a2==a&b2<b)
      {
        b3<-b2+ceiling((b-b2)/((b2-a2)/Dstar))*(b2-a2)/Dstar
        hist(x,breaks=seq(a2,b3,(b2-a2)/Dstar),freq=freq, right=right, xlim=c(a2,b2), col=col, border=border, xlab=xlab, ylab=ylab, main=main)
        points(b2,0,col="black",pch=20)
      }
      if(a2>a&b2<b)
      {
        a3<-a2-ceiling((a2-a)/((b2-a2)/Dstar))*(b2-a2)/Dstar
        b3<-b2+ceiling((b-b2)/((b2-a2)/Dstar))*(b2-a2)/Dstar
        hist(x,breaks=seq(a3,b3,(b2-a2)/Dstar),freq=freq, right=right, xlim=c(a2,b2), col=col, border=border, xlab=xlab, ylab=ylab, main=main)
        points(a2,0,col="black",pch=20)
        points(b2,0,col="black",pch=20)
      }
    }
  }
}
```

```{r}
HISTSELECT2(Z,col="pink",border="blue", freq=FALSE)
lines(x,dZ,t='l', col='red',xlim=c(-1,2))
```
# Autres exemples avec sélection automatique

###exemple simulé (mélange de Gaussiennes)
```{r}
n<-10000
y<-rbinom(n,1,0.4)
x<-y*rnorm(n)+(1-y)*rnorm(n,4)
HISTSELECT2(x,col="pink",border="blue", freq=FALSE)
curve(0.4*dnorm(x)+0.6*dnorm(x,4), add=TRUE)
hist(x, freq=FALSE)
curve(0.4*dnorm(x)+0.6*dnorm(x,4), add=TRUE)
HISTSELECT2(x,col="pink",border="blue", freq=FALSE, -1.5,5)
curve(0.4*dnorm(x)+0.6*dnorm(x,4), add=TRUE)
```
```{r}
###exemple simulé (loi de Cauchy)
n<-3000
x<-rcauchy(n)
HISTSELECT2(x,col="pink",border="blue", freq=FALSE)
curve(dcauchy(x), add=TRUE)
hist(x, freq=FALSE)
curve(dcauchy(x), add=TRUE)
HISTSELECT2(x,col="pink",border="blue", freq=FALSE, -10,10)
curve(dcauchy(x), add=TRUE)
```


# EXERCICE 4

## Partie A : simulation des données
```{r}
n=10^3
x <- seq(-5,7.5, l=2000)
```
## question 1
```{r}
Y <- rnorm(n, mean=2.5)
dY <- dnorm(x, mean=2.5, sd=1)
plot(x,dY,t='l', col='red')
```
## question 2-a)
```{r}
Mu <- c(1,3,4)
Sd <- c(0.5,0.3,0.2)
dX <- 0.2*dnorm(x, mean=Mu[1], sd=Sd[1]) +0.5*dnorm(x, mean=Mu[2], sd=Sd[2])+0.3*dnorm(x,mean=Mu[3], sd=Sd[3])
plot(x,dX,t='l', col='red')
```
## question 2-b)
```{r}
U <- sample(x=c(1,2,3), size=n, replace=TRUE, prob=c(0.2,0.5,0.3))
X <- vector(l=n)
for(i in 1:n) X[i] <- rnorm(1, mean=Mu[U[i]], sd=Sd[U[i]])
```


## Partie B : estimation par histogrammes

## question 1-a)
```{r}
hist(Y,12,freq=F)
lines(x,dY,t='l', col='red',ylim=c(0,0.45))
par(mfrow=c(2,2))
for(D in c(5,15, 50, 300)){
  hist(Y,D, freq=F)
  lines(x,dY,t='l', col='red',ylim=c(0,0.45))
} # D ideal est entre 15 et 50
```
## question 3-4)
```{r}
par(mfrow=c(2,2))
for(D in c(5,15, 50, 300)){
  hist(X,D, freq=F,ylim=c(0,0.80))
  lines(x,dX,t='l', col='red',ylim=c(0,0.80))
} # le meilleur est pour D=50
# il faut un D plus grand pour bien estimer le mélange de gaussiennes que pour estimer une seule gaussienne
```

## question 5)
```{r}
library(histogram)
par(mfrow=c(1,2))
histogram(Y, type='irregular', verbose=F,ylim=c(0,0.65))
lines(x,dY,t='l', col='red')
histogram(X, type='irregular', verbose=F,ylim=c(0,0.65))
lines(x,dX,t='l', col='red',ylim=c(0,0.50))

```
il a besoin de plus de classe(D plus grand) pour estimer le melange de gaussienne que pour estimer la gaussienne

#exercice 4 partie C estimateur à noyau
## question 1-a)
```{r}
kernY <- density(Y)# par defaut c'est le noyau gaussien
plot(kernY,ylim=c(0,0.45))
lines(x,dY,t='l', col='red')
```

# Choix des fenêtres dans l'estimateur à noyau
## question 1-b)
```{r}
kernY$bw (h du cours)
```

## question 1-c)
```{r}
bw.nrd0(Y) #valeur par défaut
bw.nrd(Y)
bw.bcv(Y) # méthode qui nous intéresse le plus (il fait un grille de h et le h optimal peut ne pas etre dans la grille du coup il faut l'affiner)
bw.ucv(Y) # méthode qui nous intéresse le plus
bw.SJ(Y)
# les trois autres méthodes n'ont pas de fondements théoriques
```

## question 1-d)
```{r}
par(mfrow=c(2,2))
for(b in c(0.01,0.1, 0.22, 2)){
                plot(density(Y,bw=b),ylim=c(0,0.6))
        lines(x,dY,t='l', col='red')
}
# 0.01 et 0.1=> trop grosse variance
# 0.22 proche des fenêtres proposées
# 2 trop gros biais
# h joue le même rôle que 1/D dans l'histogramme
```

pour le melange de gaussien le h optimal est plus pétit (faire la liaison de h avec 1/D où D est le nombre de classe dans la methode avec histogramme)

## question 1-d)
```{r}
par(mfrow=c(2,2))
for(b in c(0.01,0.1, 0.22, 2)){
                plot(density(Y,bw=b),ylim=c(0,0.6))
        lines(x,dY,t='l', col='red')
}
# 0.01 et 0.1=> trop grosse variance
# 0.22 proche des fenêtres proposées
# 2 trop gros biais
# h joue le même rôle que 1/D dans l'histogramme
```

## question 2)
```{r}
kernX <- density(X)
plot(kernX)
lines(x,dX,t='l', col='red')
kernX$bw #le h optimal trouvé par R pour estimer la densité du mélange de gaussienne est plus petit que celui pour estimer la densité de la gaussiene. ça rejoint ce que nous avions vu pour les histogrammes (D optimal plus grand pour estimer le mélange de gaussienne que pour estimer la gaussienne, Rq: h joue le même rôle que 1/D)
bw.nrd0(X)
bw.nrd(X)
bw.bcv(X)
bw.ucv(X)
bw.SJ(X)

par(mfrow=c(2,2))
for(b in c(0.02,0.08, 0.2, 2)){
                plot(density(X,bw=b),ylim=c(0,0.7))
        lines(x,dX,t='l', col='red')
}
```

## question 3)
```{r}
N=10^5
P <- sample(x=c(1,2,3), size=N, replace=TRUE, prob=c(0.2,0.5,0.3))
X1 <- vector(l=N)
#Mu <- c(mu1,mu2,mu3)
#Sd <- c(sd1,sd2,sd3)
for(i in 1:N) X1[i] <- rnorm(1, mean=Mu[P[i]], sd=Sd[P[i]])

par(mfrow=c(2,2))
for(h in c(0.05,0.2,0.4,0.8)){
        plot(x,dX, col='red', t='l')
        d <- density(X1, bw=h)
        lines(d)
        #lines(x, dX, col='red')

}
```

#exercice 3

```{r}
data("geyser")
str(geyser)
attach(geyser,warn.conflicts = FALSE)
glimpse(geyser)
```

```{r}
par(mfrow = c(2,2))#breaks c'est le nombre de classe uniforme si on donne un vecteur ,on definit nos classe

hist(waiting,col="cornflowerblue", prob=T, breaks = 5, main = "histogramme en densité de probabilité", xlab= "5 breaks")

hist(waiting,col="cornflowerblue", prob=T, breaks = 10, main = "histogramme en densité de probabilité", xlab= "10 breaks")

hist(waiting,col="cornflowerblue", prob=T, breaks = 30, main = "histogramme en densité de probabilité", xlab= "30 breaks")

HISTSELECT2(waiting,col= "pink")

```

# Estimation par histogramme avec la fonction $hist$ et $HISTSELECT2$
```{r}
par(mfrow=c(2,2))
hist(waiting,col="cornflowerblue",proba=T, breaks=5, main="Histogramme en densité de probabilité", xlab="5 breaks")
hist(waiting,col="cornflowerblue",proba=T, breaks=10, main="Histogramme en densité de probabilité", xlab="10 breaks")
hist(waiting,col="cornflowerblue",proba=T, breaks=30, main="Histogramme en densité de probabilité",xlab="30 breaks")
HISTSELECT2(waiting,col="pink",border="blue", freq=FALSE,40,110)
# Doptimal choisi est 14
```

```{r}
hist(waiting,col="cornflowerblue",proba=T, breaks=299, main="Histogramme en densité de probabilité",
     xlab="299 breaks") #un baton par observation=> NON
par(mfrow=c(1,3))
hist(waiting,col="cornflowerblue",proba=T, breaks=299, main="Histogramme en densité de probabilit",
     xlab="70 breaks")
hist(waiting,col="cornflowerblue",proba=T, breaks=30, main="Histogramme en densité de probabilité",
     xlab="30 breaks")
hist(waiting,col="cornflowerblue",proba=T, breaks=3, main="Histogramme en densité de probabilité",
     xlab="3 breaks")
```

# Avec ggplot
```{r}
library(ggplot2)
ggplot() + geom_histogram(aes(x=waiting, y=(..count..)*100/sum(..count..),color="red", fill="red"), fill="red", alpha=.4, colour="red", data=geyser,bins=14)+
  coord_cartesian(xlim = c(40,110))+ xlab("waiting")+ ylab("pourcentage (%) ")+
  labs(title="histogramme de la variable waiting ",x="waiting", y = "Pourcentage") + theme(plot.title = element_text(face = "bold"))+ theme(plot.title = element_text(hjust = 0.5))
```
# tout recommencer avec ggplot2

```{r}
library(ggplot2)
ggplot() + geom_histogram(aes(x=waiting, y=(..count..)*100/sum(..count..),color="red", fill="red"), fill="red", alpha=.4, colour="red", data=geyser,bins=14)+
  coord_cartesian(xlim = c(40,110))+ xlab("waiting")+ ylab("pourcentage (%) ")+
  labs(title="histogramme de la variable waiting ",x="waiting", y = "Pourcentage") + theme(plot.title = element_text(face = "bold"))+ theme(plot.title = element_text(hjust = 0.5))
ggplot() + geom_histogram(aes(x=waiting, y=(..count..)*100/sum(..count..),color="red", fill="red"), fill="red", alpha=.4, colour="red", data=geyser,bins=20)+
  coord_cartesian(xlim = c(40,110))+ xlab("waiting")+ ylab("pourcentage (%) ")+
  labs(title="histogramme de la variable waiting ",x="waiting", y = "Pourcentage") + theme(plot.title = element_text(face = "bold"))+ theme(plot.title = element_text(hjust = 0.5))
```
